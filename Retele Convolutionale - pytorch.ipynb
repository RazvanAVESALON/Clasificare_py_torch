{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  Rețele Convoluționale - Convolutional Neural Networks (CNNs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"1.-Introducere\">1. Introducere<a class=\"anchor-link\" href=\"#1.-Introducere\">¶</a></h2><p>In lucrarea trecuta s-a studiat problema clasificării unei baze de date simple (MNIST) cu ajutorul unei rețele de tip perceptron multistrat (Multilayer Perceptron - MLP). Pe parcursul acestui studiu de caz s-au abordat pașii elementari pentru rezolvarea unei astfel de probleme (alegerea arhitecturii, a funcției <i>loss</i>, a optimizatorului, a ratei de învățare, împărțirea bazei de date in <i>batch-uri</i> precum si bucla de învățare.</p>\n",
    "\n",
    "<p>In continuare, soluția simplă din laboratorul trecut va fi extinsă prin folosirea arhitecturilor mult mai puternice de tip rețele convoluționale (CNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"2.-Motivație-și-aspecte-generale\">2. Motivație și aspecte generale<a class=\"anchor-link\" href=\"#2.-Motivatie-si-aspecte-generale\">¶</a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Rețeaua neuronală folosită anterior a utilizat drept trăsături de intrare chiar pixelii constituenți ai imaginilor. Deși rezultatele au fost satisfăcătoare, acest deznodământ nu ar fi fost la fel de probabil pentru baze de date mai complicate. \n",
    "In general, valorile directe ale pixelilor nu sunt considerate a fi trăsături puternice. Cu acest scop se utilizează extractoare de trăsături, precum Histogram of Oriented Gradients (HOG) si Local binary patterns (LBP), care surprind mai bine informatia spațială din fiecare zonă de interes sau din jurul fiecărui pixel.</p>\n",
    "\n",
    "<img src=\"image.png\"/><center>\n",
    "<img src=\"image2.png\"/><center>\n",
    "<img src=\"FeatureFace.jpg\"/><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning \n",
    "\n",
    "<p> Deep Learning este in momentul de fata cea mai des utilizata tehnica de machine learning deoarece permite invatarea unor reprezentari complexe prin intermediul retelelor neurale. Elementul principal al rețelelor neuronale este stratul. Stratul de neuroni este practic un modul de procesare a informatiei (puteti sa il vedeti ca un filtru aplicat pe datele de intrare). Astfel, datele intra intr-un strat, sunt procesate si transmise mai departe sub o alta forma. Mai exact, straturile extrag reprezentări din date, reprezentări care sunt mai semnificative pentru problema pe care vrem sa o rezolvam.\n",
    "</p>\n",
    "\n",
    "<img src=\"features.png\"/>\n",
    "\n",
    " In computer vision filtrarea se realizeaza prin intermediul operatiei de convolutie.\n",
    " \n",
    "<img src=\"filter.png\"/>\n",
    "\n",
    "<img src=\"filtering.png\"/>\n",
    "\n",
    "Ideea de convolutie a fost astfel adaptata in reteaua neurala prin intermediul stratului convolutional.\n",
    "\n",
    "## Rețele convoluționale\n",
    "<p>Rețelele convoluționale au adus o serie de îmbunătățiri in ceea ce privește algoritmii de <i>machine learning</i>. O parte dintre acestea vor fi discutate ulterior. Drept punct de plecare se va face referire la schema generala a unei rețele convoluționale:\n",
    "<img src=\"cnn.jpeg\"/></p><center>Schema generala a unei rețele convoluționale</center>\n",
    "<p>Se pot observa doua zone principale:</p>\n",
    "<ul>\n",
    "<li>Prima, formata din straturile de tip Convolution si Pooling</li>\n",
    "<li>A doua, formata din straturi <i>Fully Connected (Linear)</i> - straturi de neuroni clasici</li>\n",
    "</ul>\n",
    "<p>Prima zona s-a dovedit a avea rolul de extractor de trăsături. Primele straturi convoluționale extrag informații de tip contururi, iar acestea devin mai complexe odată cu parcurgerea rețelei. S-a observat ca trăsăturile ieșite după prima zona a rețelei sunt puternice, in general fiind mai reprezentative decât trăsăturile obținute prin aplicarea algoritmilor HoG sau LBP.</p>\n",
    "<p>A doua zona, cu straturile <i>Fully Connected</i> este practic o rețea MLP aplicata trăsăturilor extrase de zona convoluțională a rețelei.</p>\n",
    "\n",
    "<h3 id=\"2.1.-Straturile-convolutionale\">2.1. Straturile <i>convoluționale</i><a class=\"anchor-link\" href=\"#2.1.-Straturile-convolutionale\">¶</a></h3><p>Acest tip de strat este unitatea de baza din noile arhitecturi. Făcând o analogie cu procedeele consacrate din prelucrarea imaginilor, un strat convoluțional realizează o serie de operații de filtrare liniara pe matricea de la intrarea in strat. Aceasta matrice poate fi imaginea in sine, sau rezultatul altui strat, denumit <i>feature map</i> (harta de trăsături). Un fapt relevant in acest caz este ca filtrul de convoluție are adâncimea matricei de la intrare (ex. 3 pentru o imagine RGB).\n",
    "    \n",
    "<img src=\"conv.png\"/>  \n",
    "    \n",
    "De la modul in sine in care funcționează stratul convoluțional se pot observa diferențe fata de modul de funcționare al MLP, precum si proprietăți relevante:</p>\n",
    "<ul>\n",
    "<li><i>sparse interactions</i> (interactiuni \"rare\"): spre deosebire de MLP, unde fiecare neuron din stratul $N$ interacționa cu toți neuronii din stratul $N+1$, la un CNN doar o serie de neuroni din stratul curent vor participa la neuronul din stratul următor (zona denumita câmpul receptiv, <i>receptive field</i>). Acest fapt implica stocarea a mai putini parametri, si implicit operații mai puține;</li>\n",
    "<li>partajarea parametrilor: filtrul de convoluție este folosit pentru întreaga imagine, deci ponderile care conduc la un anume neuron din stratul următor sunt mereu aceleași. Aceasta trăsătura este pusa in contrast cu arhitectura MLP, unde fiecare pondere era folosita o singura data, pentru o pereche anume de neuroni;</li>\n",
    "<li>echivarianta la translatie a reprezentarilor: se refera la proprietatea ca daca imaginea de intrare suferă o transformare de tip translație, si harta de trăsături de ieșire va suferi aceeași modificare.</li>\n",
    "</ul>\n",
    "<p>Pentru a crea un strat convoluțional in Keras se folosește sintaxa:</p>\n",
    "\n",
    "<p><code>conv_x = torch.nn.Conv2d(in_channels, out_channels, kernel_size = [linii_filtru, coloane_filtru], stride=(pas_orizontal, pas_vertical), padding = 'same')(input)</code></p>\n",
    "<p>Forma corecta pentru <code>input</code> este de tipul <code>[nr_imag,linii,coloane,canale]</code>\n",
    "Argumentul <code>strides</code> se refera la pasul pe care îl face filtrul convoluțional după ce operează asupra zonei curente. Un pas de <code>(1,1)</code> înseamnă ca va parcurge toți neuronii.\n",
    "Argumentul <code>padding</code> se leagă de capetele imaginii. Se decide daca imaginea va fi bordata cu valori de 0, astfel încât sa fie parcurși toți pixelii din imagine (<code>'same'</code>) sau se vor ignora neuronii din capetele imaginii (<code>'valid'</code>). Daca <i>padding-ul</i> este <code>'same'</code> si pasul este <code>(1,1)</code>, atunci hârțile de trăsături vor avea același număr de linii si coloane ca stratul din care provin.</p>\n",
    "\n",
    "<p>Toate straturile convoluționale sunt urmate de o funcție de activare (in general Rectified Linear Unit - ReLU) pentru care există următoarea funcție\n",
    "<code> torch.nn.ReLU()(input) </code>.\n",
    "<img src=\"acti.jpg\"/>  \n",
    "\n",
    "<h3 id=\"2.2.-Straturile-de-pooling\">2.2. Straturile de <i>pooling</i><a class=\"anchor-link\" href=\"#2.2.-Straturile-de-pooling\">¶</a></h3><p>Operația de <i>pooling</i> este cel mai bine tradusa in limba romana ca o \"grupare\", o subeșantioane. Pe scurt, aceasta operație înlocuiește valoarea unei zone din imagine/harta de trăsături cu o statistica a acelei zone. Funcția de <i>max-pooling</i> este cea mai folosita in aplicații si înlocuiește valoarea dintr-o zona bine definita cu maximul acelei zone, rezultând într-o harta de trăsături mai mica, dar care păstrează cea mai relevanta statistica. In acest mod, pe lângă reducerea dimensionalității, se obține si o invarianta la translații mici.</p>\n",
    "<p>Modul de creare a unui strat de <i>max-pooling</i> in Keras care sa ia vecinatati 2x2:<br/> \n",
    "<code>pool_x = torch.nn.MaxPool2d(kernel_size=(2, 2), stride=(2,2))(input)</code></p>\n",
    "<p>Reduce dimensiunea matricei de la intrare prin luarea valorii maxime peste fereastra definită de <code>'pool_size'</code> pentru fiecare dimensiune de-a lungul axei caracteristici. Fereastra este deplasată în fiecare dimensiune cu pasul specificat de <code>'strides'</code>.</p> \n",
    "\n",
    "<img src=\"pooling.png\"/>  \n",
    "\n",
    "<h3 id=\"2.3-Straturile-fully-connected\">2.3 Straturile <i>fully connected</i><a class=\"anchor-link\" href=\"#2.3-Straturile-fully-connected\">¶</a></h3><p>După cum a fost menționat anterior, aceste straturi sunt cele <b>dens conectate</b>, obișnuite dintr-un MLP. Deoarece hârțile de trăsături care rezultă din stratului convoluțional sau pooling sunt reprezentate ca matrici, înainte de a le putea folosi, <b>hârțile de trăsături trebuie aplatizate (vectorizate)</b>, adică matricea trebuie reprezentată ca un vector. Acest lucru se poate realizea cu funcția `view` sau cu clasa `Flatten` <br/>\n",
    "<code>flat = input.view(new_shape)</code>\n",
    "<br/>\n",
    "<code>flat = nn.Flatten()(input)</code>\n",
    "<br/>\n",
    "    \n",
    "Pentru a crea un strat dens:<br/>\n",
    "<code>fc = torch.nn.Linear(in_features = nr_neuroni_iesire_stratul_precedent, out_features = nr_neuroni_de_iesire)(input)</code><br/></p>\n",
    "\n",
    "<img src=\"feature_representation.png\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"3.-Arhitecturi-de-baza\">3. Arhitecturi de baza<a class=\"anchor-link\" href=\"#3.-Arhitecturi-de-baza\">¶</a></h2><p>Exista o multitudine de arhitecturi actuale, unele care au adus imbunatatiri marginale, altele care sunt specializate pe o anumita sarcina, dar cateva arhitecturi sunt considerate a fi pietre de temelie pentru domeniu. In continuare vor fi prezentate cateva arhitecturi care au atras o atentie foarte mare la momentul aparitiei lor.</p>\n",
    "\n",
    "<h3 id=\"3.1.-LeNet-5\">3.1. LeNet-5<a class=\"anchor-link\" href=\"#3.1.-LeNet-5\">¶</a></h3><p>Cea mai veche arhitectura convolutionala a fost prezentata in 1998 cu scopul de a recunoaste cifre scrise de mana in documente. A fost conceputa pentru imagini de rezolutie mica (32 x 32 pixeli) si, din cauza constrangerilor (la aceea vreme) cu privire la puterea de calcul, nu a prezentat o adancime mare (doar 2 straturi convolutionale cu filtre de 5 x 5 pixeli). Schema arhitecturii:\n",
    "<img src=\"lenet.png\"/></p><center>Arhitectura LeNet-5</center>\n",
    "\n",
    "<h3 id=\"3.2.-AlexNet\">3.2. AlexNet<a class=\"anchor-link\" href=\"#3.2.-AlexNet\">¶</a></h3><p>Dupa mai bine de un deceniu (in 2012), arhitectura AlexNet a fost prima arhitectura neuronala care a castigat concursul ImageNet Large Scale Visual Recognition Challenge (ILSVRC) cu o arhitectura avand 5 straturi convolutionale, imagini de intrare considerabil mai mari, filtre de convolutie mai mari in straturile initiale (11 x 11) cu pasi mai mari de parcurgere a imaginii si a folosit activari de tip <code>ReLU</code>. Aceasta arhitectura, mult mai puternica decat ce s-a vehiculat pana in acel moment , a fost antrenata cu ajutorul a doua GPU-uri performante. Schema arhitecturii:\n",
    "<img src=\"alexnet.png\"/></p><center>Arhitectura AlexNet</center>\n",
    "\n",
    "<h3 id=\"3.3-VGG\">3.3 VGG<a class=\"anchor-link\" href=\"#3.3-VGG\">¶</a></h3><p>Urmatorul pas important adus in domeniu a fost studiul impactului adancimii unei retele. In acest scop, retelele din familia VGG au demonstrat cresterea performantei odata cu adancimea. Reteaua VGG-19 (de la cele 19 straturi neuronale de orice tip) este printre cele mai mari retele utilizate in termeni de numar de parametri care trebuie invatati. In prezent, aceasta arhitectura este adesea folosita pentru trasaturile generale puternice extrase dupa ultimul strat convolutional, utile si in alte sarcini decat clasificarea. O alta observatie importanta este reprezentata de reducerea tuturor filtrelor de convolutie la dimensiunea 3 x 3 cu pas 1 la deplasare. Schema arhitecturii VGG-16:\n",
    "<img src=\"vgg16.png\"/></p><center>Arhitectura VGG-16</center>\n",
    "\n",
    "<h3 id=\"3.4.-ResNet\">3.4. ResNet<a class=\"anchor-link\" href=\"#3.4.-ResNet\">¶</a></h3><p>Aparuta mai recent ca celelalte arhitecturi prezentate, importanta acestei arhitecturi a fost uriasa, rezolvand problema <i>vanishing gradient</i>. Aceasta reprezenta scaderea puternica a gradientilor odata cu avansarea in retea in etapa de propagare inapoi. Practic, retelele cu un numar mare de straturi erau foarte greu de antrenat. Solutia acestui tip de arhitectura a fost introducerea blocului \"rezidual\", care presupunea ca la iesirea dintr-un bloc compus din mai multe convolutii se adauga si intrarea in bloc. Aceste conecxiuni de tip \"scurtatura\" (sau \"scurtcircuit\") au permis crearea unor retele mult mai adanci (inclusiv 1000 de straturi). Ca o consecinta a numarului crescut de straturi, s-a putut reduce numarul de filtre per strat, pastrand numarul de parametri care trebuiau invatati relativ redus. Arhitectura ResNet-34 este ilustrata alaturi de VGG-19 (care are un numar considerabil mai mare de parametri):\n",
    "<img src=\"resnet.png\"/></p><center>Arhitectura ResNet-34 in comparatie cu VGG-19 si o arhitectura cu 34 de straturi fara \"scurtaturi\"</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Baza de date MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyTorch version 1.10.1\n",
      "torchvision version 0.11.2\n",
      "CUDA available True\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "print(f\"pyTorch version {torch.__version__}\")\n",
    "print(f\"torchvision version {torchvision.__version__}\")\n",
    "print(f\"CUDA available {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x240c9829470>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "train_bs = 8\n",
    "test_bs = 8\n",
    "learning_rate = 0.01\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr de imagini in setul de antrenare 121\n",
      "Nr de imagini in setul de test 14\n",
      "Dim primei imagini din Dataset tensor([[[1.1414, 1.1414, 1.1414,  ..., 1.4723, 1.4596, 1.4596],\n",
      "         [1.1414, 1.1414, 1.1414,  ..., 1.4596, 1.4596, 1.4596],\n",
      "         [1.1414, 1.1414, 1.1414,  ..., 1.4978, 1.4978, 1.4978],\n",
      "         ...,\n",
      "         [1.7141, 1.7269, 1.7269,  ..., 1.7396, 1.7269, 1.7396],\n",
      "         [1.7141, 1.7269, 1.7269,  ..., 1.7523, 1.7396, 1.7523],\n",
      "         [1.7141, 1.7269, 1.7269,  ..., 1.7650, 1.7523, 1.7650]]])\n",
      "Etichete pt prima imagine 0\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "transforms = T.Compose([ \n",
    "        T.CenterCrop(1000),\n",
    "        torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "        T.ToTensor(), # converts a PIL.Image or numpy array into torch.Tensor\n",
    "       \n",
    "        T.Normalize((0.1307,), (0.3081,)), # Normalize the dataset with mean and std specified\n",
    "               ])\n",
    "data_dir=r\"D:\\ai intro\\AI intro\\5. Retele Neurale\\covid_dataset\"\n",
    "train_ds = dset.ImageFolder(data_dir+'/train',transform=transforms)\n",
    "test_ds = dset.ImageFolder(data_dir+'/test',transform=transforms)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, shuffle=True, batch_size=train_bs)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, shuffle=False, batch_size=test_bs)\n",
    "\n",
    "print(\"Nr de imagini in setul de antrenare\", len(train_ds))\n",
    "print(\"Nr de imagini in setul de test\", len(test_ds))\n",
    "\n",
    "print(\"Dim primei imagini din Dataset\", train_ds[0][0])\n",
    "print(\"Etichete pt prima imagine\", train_ds[0][1])\n",
    "\n",
    "n_classes = len(np.unique(train_ds.targets))\n",
    "print(np.unique(train_ds.targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Arhitectura rețelei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Varianta 1: API secvențial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dimension torch.Size([1, 1000, 1000])\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=valid)\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=valid)\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Flatten(start_dim=1, end_dim=-1)\n",
      "  (7): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (8): ReLU()\n",
      "  (9): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "n1 = 32 \n",
    "n2 = 64\n",
    "n3 = 128 \n",
    "image_dim = train_ds[0][0].shape\n",
    "print(\"Image dimension\", image_dim)\n",
    "\n",
    "# definim arhitectura retelei convoluționale\n",
    "network = nn.Sequential(\n",
    "    nn.Conv2d(1, n1, (5, 5), padding='valid'),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d((2, 2)),\n",
    "    nn.Conv2d(n1, n2, (5, 5), padding='valid'),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d((2, 2)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(n2*4*4, n3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(n3, n_classes)\n",
    ")\n",
    "\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Varianta 2: Moștenire clasa `torch.nn.Module` \n",
    "Este o modalitate de a crea networke care sunt mai flexibile decât torch.nn.Sequential API. Prin moștenire se pot crea rețele cu topologie neliniară, straturi partajate și chiar intrări sau ieșiri multiple. Clasa-copil trebuie să implementeze funcțiile `__init__()` pentru a instanția straturile necesare și o funcție `forward()` unde se realizează calculele, input este trecut prin straturile rețelei și/sau alte funcții."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomNet(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=valid)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=valid)\n",
      "  (linear1): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (linear2): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (max_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "n1 = 32\n",
    "n2 = 64\n",
    "n3 = 128 \n",
    "\n",
    "class CustomNet(torch.nn.Module):\n",
    "    def __init__(self, input_nc, n1, n2, n3, n_classes):\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_nc, n1, (5, 5), padding='valid')\n",
    "        self.conv2 = nn.Conv2d(n1, n2, (5, 5), padding='valid')\n",
    "        self.linear1 = nn.Linear(n2*4*4, n3) # 4*4 image dimension after 2 max_pooling\n",
    "        self.linear2 = nn.Linear(n3, n_classes)\n",
    "        self.max_pool = nn.MaxPool2d((2, 2))\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "network = CustomNet(1, n1, n2, n3, n_classes)\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Antrenarea networkului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specificarea functiei loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# definirea optimizatorului\n",
    "opt = torch.optim.Adam(network.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device  cuda:0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (8x3904576 and 1024x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# se face forward propagation -> se calculeaza predictia\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mins\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# se calculeaza eroarea/loss-ul\u001b[39;00m\n\u001b[0;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, tgs)\n",
      "File \u001b[1;32mD:\\Anaconda\\INStallle\\envs\\torch_p39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mCustomNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     21\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_pool(x)\n\u001b[0;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     25\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(x)\n",
      "File \u001b[1;32mD:\\Anaconda\\INStallle\\envs\\torch_p39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Anaconda\\INStallle\\envs\\torch_p39\\lib\\site-packages\\torch\\nn\\modules\\linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\INStallle\\envs\\torch_p39\\lib\\site-packages\\torch\\nn\\functional.py:1848\u001b[0m, in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[0;32m   1847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, weight, bias\u001b[38;5;241m=\u001b[39mbias)\n\u001b[1;32m-> 1848\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (8x3904576 and 1024x128)"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "\n",
    "total_acc = []\n",
    "total_loss = []\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device \", device)\n",
    "\n",
    "network.train()\n",
    "network.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "for ep in range(n_epochs):\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    loss_epoch = 0\n",
    "    for data in train_loader:\n",
    "        ins, tgs = data\n",
    "        ins = ins.to(device)\n",
    "        tgs = tgs.to(device)\n",
    "        # redimensionam tensor-ul input\n",
    "        # print(ins.shape)\n",
    "        # print(tgs.shape)\n",
    "        \n",
    "        # seteaza toti gradientii la zero, deoarece PyTorch acumuleaza valorile lor dupa mai multe backward passes\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # se face forward propagation -> se calculeaza predictia\n",
    "        output = network(ins)\n",
    "\n",
    "        # se calculeaza eroarea/loss-ul\n",
    "        loss = criterion(output, tgs)\n",
    "\n",
    "        # se face backpropagation -> se calculeaza gradientii\n",
    "        loss.backward()\n",
    "\n",
    "        # se actualizează weights-urile\n",
    "        opt.step()\n",
    "\n",
    "        loss_epoch = loss_epoch + loss.item()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            network.eval()\n",
    "            current_predict = network(ins)\n",
    "\n",
    "            # deoarece reteaua nu include un strat de softmax, predictia finala (cifra) trebuie calculata manual\n",
    "            current_predict = nn.Softmax(dim=1)(current_predict)\n",
    "            current_predict = current_predict.argmax(dim=1)\n",
    "\n",
    "            if 'cuda' in device.type:\n",
    "                current_predict = current_predict.cpu().numpy()\n",
    "                current_target = tgs.cpu().numpy()\n",
    "            else:\n",
    "                current_predict = current_predict.numpy()\n",
    "                current_target = tgs.numpy()\n",
    "\n",
    "            # print(current_predict.shape)\n",
    "            predictions = np.concatenate((predictions, current_predict), axis=0)\n",
    "            targets = np.concatenate((targets, current_target))\n",
    "    \n",
    "    total_loss.append(loss_epoch/train_bs)\n",
    "    \n",
    "    # print(predictions.shape)\n",
    "    # print(len(targets))\n",
    "    # Calculam acuratetea\n",
    "    acc = np.sum(predictions==targets)/len(predictions)\n",
    "    total_acc.append(acc)\n",
    "    print(f'Epoch {ep}: error {loss_epoch/train_bs} accuracy {acc*100}')\n",
    "\n",
    "    # salvam ponderile modelului dupa fiecare epoca\n",
    "    torch.save(network, 'my_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Testarea networkului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 99.07000000000001\n"
     ]
    }
   ],
   "source": [
    "# incarcam ponderile modelul antrenat\n",
    "network = torch.load('my_model.pth')\n",
    "\n",
    "test_labels = test_ds.targets.numpy()\n",
    "predictions = []\n",
    "\n",
    "network.eval()\n",
    "for data in test_loader:\n",
    "    ins, tgs = data\n",
    "    ins = ins.to(device)\n",
    "\n",
    "    current_predict = network(ins)\n",
    "    current_predict = nn.Softmax(dim=1)(current_predict)\n",
    "    current_predict = current_predict.argmax(dim=1)\n",
    "\n",
    "    if 'cuda' in device.type:\n",
    "        current_predict = current_predict.cpu().numpy()\n",
    "    else:\n",
    "        current_predict = current_predict.numpy()\n",
    "    predictions = np.concatenate((predictions, current_predict))\n",
    "\n",
    "acc = np.sum(predictions == test_labels)/len(predictions)\n",
    "print(f'Test accuracy is {acc*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercițiu\n",
    "\n",
    "Antrenați o rețea convoluțională pentru diagnosticarea COVID-19 în radiografii pulmonare și raportați performanțele pe setul de testare. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
